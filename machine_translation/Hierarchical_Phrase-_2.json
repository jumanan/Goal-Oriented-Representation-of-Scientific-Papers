"{\"paper\": {\"status\": \"map_fixed\", \"title\": \"Hierarchical Phrase-Based Translation Representations\", \"url\": \"http://www.aclweb.org/anthology/D11-1127\", \"abstract\": \"This paper compares several translation representations for a synchronous context-free grammar parse including CFGs/hypergraphs, finite-state automata (FSA), and pushdown automata (PDA).The representation choice is shown to determine the form and complexity of target LM intersection and shortest-path algorithms that follow.Intersection, shortest path, FSA expansion and RTN replacement algorithms are presented for PDAs.Chinese-to- English translation experiments using HiFST and HiPDT, FSA and PDA-based decoders, are presented using admissible (or exact) search, possible for HiFST with compact SCFG rulesets and HiPDT with compact LMs.For large rulesets with large LMs, we introduce a two-pass search strategy which we then analyze in terms of search errors and translation performance.\\n\", \"field\": \"Machine Translation\", \"user\": \"MT-admin_Gonzalo_Iglesias\"}, \"map_name\": \"Hierarchical_Phrase-_2.html\", \"_id\": {\"$oid\": \"5858b889dc9e6c4509cf038d\"}, \"annotation\": {\"metrics\": [{\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, {\"type\": \"Qualitative\", \"name\": \"machine translation_time\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"time\"}, {\"type\": \"Qualitative\", \"name\": \"machine translation_space\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"space\"}], \"tasks\": [{\"name\": \"translation representations\", \"abstraction_level\": \"abstract\"}, {\"name\": \"\\ufb01nite-state automata (FSA)\", \"abstraction_level\": \"abstract\"}, {\"name\": \"pushdown automata (PDA)\", \"abstraction_level\": \"abstract\"}, {\"name\": \"HiFST\", \"abstraction_level\": \"abstract\"}, {\"name\": \"HiPDT\", \"abstraction_level\": \"abstract\"}, {\"name\": \"Hierarchical phrase-based translation\", \"abstraction_level\": \"abstract\"}, {\"name\": \"n-gram target language model (LM)\", \"abstraction_level\": \"moderate\"}, {\"name\": \"machine translation\", \"abstraction_level\": \"abstract\"}, {\"name\": \"decoding\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiFST (G1 + M1\\u03b8)\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiFST (G1 + M1) - Baseline\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiPDT (G2 + M1\\u03b8)\", \"abstraction_level\": \"moderate\"}, {\"name\": \"synchronous context-free translation grammar (SCFG)\", \"abstraction_level\": \"specific\"}, {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, {\"name\": \"G2 - G 2\", \"abstraction_level\": \"specific\"}, {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\", \"abstraction_level\": \"moderate\"}, {\"name\": \"a lattice-based decoder implemented with weighted finite-state transducers - de Gispert et al., 2010\", \"abstraction_level\": \"specific\"}, {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, {\"name\": \"HiFST (G1 + M1) + M2\", \"abstraction_level\": \"moderate\"}], \"datasets\": [{\"comment\": \"GALE - 1755 , portions of MT02 through MT06\", \"name\": \"tune-nw\", \"language\": \"Chinese|English\", \"field\": \"\", \"type\": \"\", \"size\": \"1755 sentences\"}, {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}], \"results\": [{\"value\": \"x\", \"metric_name\": {\"type\": \"Qualitative\", \"name\": \"machine translation_time\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"time\"}, \"dataset_name\": \"\", \"task_name\": {\"name\": \"pushdown automata (PDA)\"}}, {\"value\": \"x\", \"metric_name\": {\"type\": \"Qualitative\", \"name\": \"machine translation_time\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"time\"}, \"dataset_name\": \"\", \"task_name\": {\"name\": \"\\ufb01nite-state automata (FSA)\"}}, {\"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"value\": 26.3, \"task_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8)\"}}, {\"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"value\": 34.8, \"task_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\"}}, {\"value\": 36.1, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}}, {\"value\": 34.5, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiFST (G1 + M1) - Baseline\"}}, {\"value\": 32.8, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiFST (G1 + M1\\u03b8)\"}}, {\"value\": 34.5, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\"}}, {\"value\": 35.6, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}}, {\"value\": 35.6, \"metric_name\": {\"type\": \"Quantitative\", \"name\": \"machine translation_BLEU\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"BLEU\"}, \"dataset_name\": {\"comment\": \"GALE - 1671, portions of MT02 through MT06\", \"field\": \"\", \"name\": \"test-nw\", \"language\": \"Chinese|English\", \"size\": \"1671 sentences\"}, \"task_name\": {\"name\": \"HiFST (G1 + M1) + M2\"}}, {\"value\": \"y\", \"dataset_name\": \"\", \"task_name\": {\"name\": \"\\ufb01nite-state automata (FSA)\", \"abstraction_level\": \"abstract\"}, \"metric_name\": {\"type\": \"Qualitative\", \"name\": \"machine translation_space\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"space\"}}, {\"value\": \">y\", \"dataset_name\": \"\", \"task_name\": {\"name\": \"pushdown automata (PDA)\", \"abstraction_level\": \"abstract\"}, \"metric_name\": {\"type\": \"Qualitative\", \"name\": \"machine translation_space\", \"task_name\": {\"name\": \"machine translation\"}, \"measure\": \"space\"}}], \"relations\": [{\"task1_name\": {\"name\": \"translation representations\"}, \"task2_name\": {\"name\": \"\\ufb01nite-state automata (FSA)\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"translation representations\"}, \"task2_name\": {\"name\": \"pushdown automata (PDA)\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"decoding\"}, \"task2_name\": {\"name\": \"a lattice-based decoder implemented with weighted finite-state transducers - de Gispert et al., 2010\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"decoding\"}, \"task2_name\": {\"name\": \"HiPDT\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"machine translation\"}, \"task2_name\": {\"name\": \"Hierarchical phrase-based translation\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"HiFST\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8)\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"HiFST\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) - Baseline\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"HiPDT\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8)\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"n-gram target language model (LM)\"}, \"task2_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"n-gram target language model (LM)\"}, \"task2_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"synchronous context-free translation grammar (SCFG)\"}, \"task2_name\": {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"synchronous context-free translation grammar (SCFG)\"}, \"task2_name\": {\"name\": \"G2 - G 2\", \"abstraction_level\": \"specific\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) - Baseline\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) - Baseline\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8)\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"G2 - G 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8)\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiFST (G1 + M1) - Baseline\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8)\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"\\ufb01nite-state automata (FSA)\"}, \"task2_name\": {\"name\": \"HiFST\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"\\ufb01nite-state automata (FSA)\"}, \"task2_name\": {\"name\": \"HiPDT\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"pushdown automata (PDA)\"}, \"task2_name\": {\"name\": \"HiPDT\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"a lattice-based decoder implemented with weighted finite-state transducers - de Gispert et al., 2010\"}, \"task2_name\": {\"name\": \"HiFST\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"decoding\"}, \"task2_name\": {\"name\": \"machine translation\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8)\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8)\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"n-gram target language model (LM)\"}, \"task2_name\": {\"name\": \"Hierarchical phrase-based translation\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"synchronous context-free translation grammar (SCFG)\"}, \"task2_name\": {\"name\": \"Hierarchical phrase-based translation\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"Hierarchical phrase-based translation\"}, \"task2_name\": {\"name\": \"HiFST\", \"abstraction_level\": \"abstract\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"Hierarchical phrase-based translation\"}, \"task2_name\": {\"name\": \"HiPDT\", \"abstraction_level\": \"abstract\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"HiFST\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiFST\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiPDT\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"G2 - G 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M1 - M 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M1\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiPDT\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"G2 - G 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"entropy-based pruning of the language model - Stolcke, 1998\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiPDT (G2 + M1\\u03b8) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiFST\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) + M2\"}, \"relation_type\": \"is achieved by\"}, {\"task1_name\": {\"name\": \"G1 - G 1\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"M2 - M 2\", \"abstraction_level\": \"specific\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) + M2\"}, \"relation_type\": \"is a subtask of\"}, {\"task1_name\": {\"name\": \"HiFST (G1 + M1\\u03b8) + M2\", \"abstraction_level\": \"moderate\"}, \"task2_name\": {\"name\": \"HiFST (G1 + M1) + M2\"}, \"relation_type\": \"is a subtask of\"}]}, \"time\": \" 2/25/2018, 2:22:28 PM\"}"